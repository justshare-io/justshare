Index: examples/stream/stream.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/examples/stream/stream.cpp b/examples/stream/stream.cpp
--- a/examples/stream/stream.cpp	(revision fb0a24fba21afe316b034ca5ef4d26bb66e98e3d)
+++ b/examples/stream/stream.cpp	(date 1693643392609)
@@ -6,6 +6,7 @@
 #include "common.h"
 #include "common-sdl.h"
 #include "whisper.h"
+#include "json.hpp"
 
 #include <cassert>
 #include <cstdio>
@@ -13,6 +14,13 @@
 #include <thread>
 #include <vector>
 #include <fstream>
+#include <sys/time.h>
+
+long long current_time_millis() {
+    struct timeval tv;
+    gettimeofday(&tv, NULL);
+    return (long long)tv.tv_sec * 1000 + tv.tv_usec / 1000;
+}
 
 //  500 -> 00:05.000
 // 6000 -> 01:00.000
@@ -51,7 +59,6 @@
 
     std::string language  = "en";
     std::string model     = "models/ggml-base.en.bin";
-    std::string fname_out;
 };
 
 void whisper_print_usage(int argc, char ** argv, const whisper_params & params);
@@ -80,7 +87,6 @@
         else if (arg == "-kc"  || arg == "--keep-context")  { params.no_context    = false; }
         else if (arg == "-l"   || arg == "--language")      { params.language      = argv[++i]; }
         else if (arg == "-m"   || arg == "--model")         { params.model         = argv[++i]; }
-        else if (arg == "-f"   || arg == "--file")          { params.fname_out     = argv[++i]; }
         else if (arg == "-tdrz" || arg == "--tinydiarize")  { params.tinydiarize   = true; }
 
         else {
@@ -115,11 +121,66 @@
     fprintf(stderr, "  -kc,      --keep-context  [%-7s] keep context between audio chunks\n",              params.no_context ? "false" : "true");
     fprintf(stderr, "  -l LANG,  --language LANG [%-7s] spoken language\n",                                params.language.c_str());
     fprintf(stderr, "  -m FNAME, --model FNAME   [%-7s] model path\n",                                     params.model.c_str());
-    fprintf(stderr, "  -f FNAME, --file FNAME    [%-7s] text output file name\n",                          params.fname_out.c_str());
     fprintf(stderr, "  -tdrz,     --tinydiarize  [%-7s] enable tinydiarize (requires a tdrz model)\n",     params.tinydiarize ? "true" : "false");
     fprintf(stderr, "\n");
 }
 
+struct Token {
+    uint32_t id;
+//    float p;
+    uint64_t start_time;
+    uint64_t end_time;
+    std::string text;
+
+    // Convert this struct to JSON
+    friend void to_json(nlohmann::json& j, const Token& token) {
+        j = nlohmann::json{
+            {"id", token.id},
+//            {"p", token.p},
+            {"start_time", token.start_time},
+            {"end_time", token.end_time},
+            {"text", token.text}
+        };
+    }
+
+    // Populate this struct from JSON
+    friend void from_json(const nlohmann::json& j, Token& token) {
+        j.at("id").get_to(token.id);
+//        j.at("p").get_to(token.p);
+        j.at("start_time").get_to(token.start_time);
+        j.at("end_time").get_to(token.end_time);
+        j.at("text").get_to(token.text);
+    }
+};
+
+struct Segment {
+    uint32_t num;
+    std::vector<Token> tokens;
+    std::string text;
+    uint64_t start_time;
+    uint64_t end_time;
+
+    // Convert this struct to JSON
+    friend void to_json(nlohmann::json& j, const Segment& segment) {
+        j = nlohmann::json{
+            {"num", segment.num},
+            {"tokens", segment.tokens},
+            {"text", segment.text},
+            {"start_time", segment.start_time},
+            {"end_time", segment.end_time},
+        };
+    }
+
+    // Populate this struct from JSON
+    friend void from_json(const nlohmann::json& j, Segment& segment) {
+        j.at("num").get_to(segment.num);
+        j.at("tokens").get_to(segment.tokens);
+        j.at("text").get_to(segment.text);
+        j.at("start_time").get_to(segment.start_time);
+        j.at("end_time").get_to(segment.end_time);
+    }
+};
+
 int main(int argc, char ** argv) {
     whisper_params params;
 
@@ -139,7 +200,7 @@
 
     const int n_new_line = !use_vad ? std::max(1, params.length_ms / params.step_ms - 1) : 1; // number of steps to print new line
 
-    params.no_timestamps  = !use_vad;
+    params.no_timestamps  = false;
     params.no_context    |= use_vad;
     params.max_tokens     = 0;
 
@@ -170,54 +231,51 @@
     std::vector<whisper_token> prompt_tokens;
 
     // print some info about the processing
-    {
-        fprintf(stderr, "\n");
-        if (!whisper_is_multilingual(ctx)) {
-            if (params.language != "en" || params.translate) {
-                params.language = "en";
-                params.translate = false;
-                fprintf(stderr, "%s: WARNING: model is not multilingual, ignoring language and translation options\n", __func__);
-            }
-        }
-        fprintf(stderr, "%s: processing %d samples (step = %.1f sec / len = %.1f sec / keep = %.1f sec), %d threads, lang = %s, task = %s, timestamps = %d ...\n",
-                __func__,
-                n_samples_step,
-                float(n_samples_step)/WHISPER_SAMPLE_RATE,
-                float(n_samples_len )/WHISPER_SAMPLE_RATE,
-                float(n_samples_keep)/WHISPER_SAMPLE_RATE,
-                params.n_threads,
-                params.language.c_str(),
-                params.translate ? "translate" : "transcribe",
-                params.no_timestamps ? 0 : 1);
-
-        if (!use_vad) {
-            fprintf(stderr, "%s: n_new_line = %d, no_context = %d\n", __func__, n_new_line, params.no_context);
-        } else {
-            fprintf(stderr, "%s: using VAD, will transcribe on speech activity\n", __func__);
-        }
-
-        fprintf(stderr, "\n");
-    }
+//    {
+//        fprintf(stderr, "\n");
+//        if (!whisper_is_multilingual(ctx)) {
+//            if (params.language != "en" || params.translate) {
+//                params.language = "en";
+//                params.translate = false;
+//                fprintf(stderr, "%s: WARNING: model is not multilingual, ignoring language and translation options\n", __func__);
+//            }
+//        }
+//        fprintf(stderr, "%s: processing %d samples (step = %.1f sec / len = %.1f sec / keep = %.1f sec), %d threads, lang = %s, task = %s, timestamps = %d ...\n",
+//                __func__,
+//                n_samples_step,
+//                float(n_samples_step)/WHISPER_SAMPLE_RATE,
+//                float(n_samples_len )/WHISPER_SAMPLE_RATE,
+//                float(n_samples_keep)/WHISPER_SAMPLE_RATE,
+//                params.n_threads,
+//                params.language.c_str(),
+//                params.translate ? "translate" : "transcribe",
+//                params.no_timestamps ? 0 : 1);
+//
+//        if (!use_vad) {
+//            fprintf(stderr, "%s: n_new_line = %d, no_context = %d\n", __func__, n_new_line, params.no_context);
+//        } else {
+//            fprintf(stderr, "%s: using VAD, will transcribe on speech activity\n", __func__);
+//        }
+//
+//        fprintf(stderr, "\n");
+//    }
 
     int n_iter = 0;
 
     bool is_running = true;
 
     std::ofstream fout;
-    if (params.fname_out.length() > 0) {
-        fout.open(params.fname_out);
-        if (!fout.is_open()) {
-            fprintf(stderr, "%s: failed to open output file '%s'!\n", __func__, params.fname_out.c_str());
-            return 1;
-        }
-    }
 
-    printf("[Start speaking]");
     fflush(stdout);
 
-          auto t_last  = std::chrono::high_resolution_clock::now();
+    auto t_last  = std::chrono::high_resolution_clock::now();
     const auto t_start = t_last;
 
+    long long start_time = current_time_millis();
+    long long current_time = 0;
+
+    long marker = 0;
+
     // main audio loop
     while (is_running) {
         // handle Ctrl + C
@@ -229,6 +287,8 @@
 
         // process new audio
 
+        current_time = current_time_millis() - start_time;
+
         if (!use_vad) {
             while (true) {
                 audio.get(params.step_ms, pcmf32_new);
@@ -252,7 +312,7 @@
             // take up to params.length_ms audio from previous iteration
             const int n_samples_take = std::min((int) pcmf32_old.size(), std::max(0, n_samples_keep + n_samples_len - n_samples_new));
 
-            //printf("processing: take = %d, new = %d, old = %d\n", n_samples_take, n_samples_new, (int) pcmf32_old.size());
+//            printf("n_samples_new = %d, n_samples_take = %d, n_samples_old = %d, n_samples_len = %d\n", n_samples_new, n_samples_take, (int) pcmf32_old.size(), n_samples_len);
 
             pcmf32.resize(n_samples_new + n_samples_take);
 
@@ -299,6 +359,7 @@
             wparams.max_tokens       = params.max_tokens;
             wparams.language         = params.language.c_str();
             wparams.n_threads        = params.n_threads;
+            wparams.token_timestamps = true;
 
             wparams.audio_ctx        = params.audio_ctx;
             wparams.speed_up         = params.speed_up;
@@ -320,12 +381,14 @@
             // print result;
             {
                 if (!use_vad) {
-                    printf("\33[2K\r");
+//                    printf("\33[2K\r");
+//
+//                    // print long empty line to clear the previous line
+//                    printf("%s", std::string(100, ' ').c_str());
+//
+//                    printf("\33[2K\r");
 
-                    // print long empty line to clear the previous line
-                    printf("%s", std::string(100, ' ').c_str());
-
-                    printf("\33[2K\r");
+//                    printf("clearing output\n");
                 } else {
                     const int64_t t1 = (t_last - t_start).count()/1000000;
                     const int64_t t0 = std::max(0.0, t1 - pcmf32.size()*1000.0/WHISPER_SAMPLE_RATE);
@@ -339,52 +402,48 @@
                 for (int i = 0; i < n_segments; ++i) {
                     const char * text = whisper_full_get_segment_text(ctx, i);
 
-                    if (params.no_timestamps) {
-                        printf("%s", text);
-                        fflush(stdout);
+                    Segment s;
+                    s.num = marker;
+                    s.text = whisper_full_get_segment_text(ctx, i);
 
-                        if (params.fname_out.length() > 0) {
-                            fout << text;
-                        }
-                    } else {
-                        const int64_t t0 = whisper_full_get_segment_t0(ctx, i);
-                        const int64_t t1 = whisper_full_get_segment_t1(ctx, i);
+                    const int64_t t0 = whisper_full_get_segment_t0(ctx, i);
+                    const int64_t t1 = whisper_full_get_segment_t1(ctx, i);
+                    s.start_time = t0 + current_time;
+                    s.end_time = t1 + current_time;
+
+                    const int n_tokens = whisper_full_n_tokens(ctx, i);
+                    for (int j = 0; j < n_tokens; ++j) {
+                        const char * token = whisper_full_get_token_text(ctx, i, j);
+//                            const float p = whisper_full_get_token_p(ctx, i, j);
 
-                        std::string output = "[" + to_timestamp(t0) + " --> " + to_timestamp(t1) + "]  " + text;
+                        const whisper_token_data data = whisper_full_get_token_data(ctx, i, j);
+
+                        Token t;
+                        t.id = whisper_full_get_token_id(ctx, i, j);
+                        t.text = token;
+//                            t.p = p;
+                        t.start_time = data.t0 + current_time;
+                        t.end_time = data.t1 + current_time;
+                        s.tokens.push_back(t);
+                    }
 
-                        if (whisper_full_get_segment_speaker_turn_next(ctx, i)) {
-                            output += " [SPEAKER_TURN]";
-                        }
-
-                        output += "\n";
-
-                        printf("%s", output.c_str());
-                        fflush(stdout);
-
-                        if (params.fname_out.length() > 0) {
-                            fout << output;
-                        }
+                    if (whisper_full_get_segment_speaker_turn_next(ctx, i)) {
+                        //output += " [SPEAKER_TURN]";
                     }
+                    nlohmann::json j = s;
+                    printf("%s\n", j.dump().c_str());
                 }
-
-                if (params.fname_out.length() > 0) {
-                    fout << std::endl;
-                }
-
-                if (use_vad){
-                    printf("\n");
-                    printf("### Transcription %d END\n", n_iter);
-                }
             }
 
             ++n_iter;
 
             if (!use_vad && (n_iter % n_new_line) == 0) {
-                printf("\n");
-
+                ++marker;
                 // keep part of the audio for next iteration to try to mitigate word boundary issues
                 pcmf32_old = std::vector<float>(pcmf32.end() - n_samples_keep, pcmf32.end());
 
+                //printf("keeping %lu samples\n", pcmf32_old.size());
+
                 // Add tokens of the last full length segment as the prompt
                 if (!params.no_context) {
                     prompt_tokens.clear();
